{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPLuEnVptjwctrfQ9adprQn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install gymnasium"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PedibcWYOicl","executionInfo":{"status":"ok","timestamp":1686734204242,"user_tz":-330,"elapsed":4646,"user":{"displayName":"Lukmanul Hakeem M","userId":"17183038146671070294"}},"outputId":"3f0f58e1-47f1-449d-aaf8-d9d4a91c8a7a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.28.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.22.4)\n","Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.0.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"]}]},{"cell_type":"code","source":["!pip install gymnasium[mujoco]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9V1HxJ4O0YU","executionInfo":{"status":"ok","timestamp":1686735546057,"user_tz":-330,"elapsed":5700,"user":{"displayName":"Lukmanul Hakeem M","userId":"17183038146671070294"}},"outputId":"57fb1704-bc60-4d2a-99c0-fbbc828710e3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.10/dist-packages (0.28.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (1.22.4)\n","Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (1.0.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (0.0.4)\n","Requirement already satisfied: mujoco>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.3.5)\n","Requirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.25.1)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (8.4.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.2->gymnasium[mujoco]) (1.4.0)\n","Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.2->gymnasium[mujoco]) (2.5.9)\n","Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.2->gymnasium[mujoco]) (3.1.6)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"h-XsePm6NkuV","executionInfo":{"status":"ok","timestamp":1686735550178,"user_tz":-330,"elapsed":1796,"user":{"displayName":"Lukmanul Hakeem M","userId":"17183038146671070294"}}},"outputs":[],"source":["import gym\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","#from collections import deque\n","import random"]},{"cell_type":"code","source":["class Soft_Q_Net(nn.Module):\n","  def __init__(self, observation_dim, action_dim):\n","    super(Soft_Q_Net, self).__init__()\n","    self.observation_dim = observation_dim\n","    self.action_dim = action_dim\n","    # define network architecture\n","    self.FC1 = nn.Linear(self.observation_dim+self.action_dim, 64)    # input layer\n","    self.FC2 = nn.Linear(64, 256)                     # hidden layer\n","    self.FC3 = nn.Linear(256, 1)                      # output layer\n","\n","  # network connecting\n","  def forward_pass(self, observation, action):\n","    x = torch.cat([observation, action], dim=-1)\n","    x = self.FC1(x)\n","    x = F.relu(x)\n","    x = self.FC2(x)\n","    x = F.relu(x)\n","    x = self.FC3(x)\n","    return x"],"metadata":{"id":"9gG5Pl6wQ2aO","executionInfo":{"status":"ok","timestamp":1686735554441,"user_tz":-330,"elapsed":6,"user":{"displayName":"Lukmanul Hakeem M","userId":"17183038146671070294"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class buffer_memory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.buffer = []\n","        self.position = 0\n","\n","    def store(self, transition):\n","        if len(self.buffer) < self.capacity:\n","            self.buffer.append(None)\n","        self.buffer[self.position] = transition\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        indices = np.random.choice(len(self.buffer), size=batch_size, replace=False)\n","        observations, actions, rewards, next_observations, dones = zip(*[self.buffer[i] for i in indices])\n","        return (torch.FloatTensor(observations),\n","            torch.FloatTensor(actions),\n","            torch.FloatTensor(rewards),\n","            torch.FloatTensor(next_observations),\n","            torch.FloatTensor(dones))\n","\n","    def __len__(self):\n","        return len(self.buffer)"],"metadata":{"id":"uZec97EVEbrm","executionInfo":{"status":"ok","timestamp":1686735559079,"user_tz":-330,"elapsed":603,"user":{"displayName":"Lukmanul Hakeem M","userId":"17183038146671070294"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def train(buffer, target_model, eval_model, gamma, optimizer, batch_size, loss_fn, count, update_freq):\n","  observations, actions, rewards, next_observations, dones = buffer.sample(batch_size)\n","\n","  q_vals = eval_model.forward_pass(observations, actions)                                      # get Qt values (2d tensor of two element) for all observation (observation is 2d) from eval model\n","  next_q_vals = target_model.forward_pass(next_observations, actions)                          # get Qt+1 values for all next observation from target model\n","  expected_q_vals = rewards + gamma * (1 - dones) * next_q_vals.detach()\n","\n","  loss = F.mse_loss(q_vals, expected_q_vals)\n","\n","  optimizer.zero_grad()         # set eval_model gradient to none\n","  loss.backward()               # computes the gradient w.r.t loss\n","  optimizer.step()              # Performs a single optimization step (parameter update)\n","\n","  if count % update_freq == 0:  # update target model for every 200 steps by sharing the params of eval model\n","    target_model.load_state_dict(eval_model.state_dict())\n","\n","  return loss\n",""],"metadata":{"id":"PPFMlHnOFI4c","executionInfo":{"status":"ok","timestamp":1686735564134,"user_tz":-330,"elapsed":571,"user":{"displayName":"Lukmanul Hakeem M","userId":"17183038146671070294"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## Start here\n","\n","gamma = 0.99             # discount rate\n","learning_rate = 0.001   # learning rate\n","batch_size = 128          # training batch size\n","update_freq = 200        # update target network for every 200 steps (after every 200 state)\n","capacity = 10000   # size of buffer memory\n","render = False           # renedering of cartpole window\n","episode = 1000    # Total episode\n","alpha = 0.5            # entropy/temperature coefficient\n","episodes = 1000\n","\n","env = gym.make(\"Pusher-v4\")\n","env = env.unwrapped\n","observation_dim = env.observation_space.shape[0]         # State space size: 4\n","action_dim = env.action_space.shape[0]                   # Action space size: 2\n","print(observation_dim, '||', action_dim)\n","\n","target_net = Soft_Q_Net(observation_dim, action_dim)   # initializing target nn\n","eval_net = Soft_Q_Net(observation_dim, action_dim)     # initializing evaluation nn\n","eval_net.load_state_dict(target_net.state_dict())             # loading initialized params (weights and biases) of target nn to eval nn\n","\n","optimizer = torch.optim.Adam(eval_net.parameters(), lr=learning_rate)   # optimizer\n","buffer = buffer_memory(capacity)                                        # initialize buffer memory\n","loss_fn = nn.MSELoss()\n","\n","count = 0\n","weight_reward = None\n","\n","for i in range(episode):\n","  # within each episode\n","  obs = env.reset()     # get initial state observation from env\n","  reward_total = 0      # total reward got in a episode\n","  episode_reward = 0\n","  episode_steps = 0\n","  if render:\n","    env.render()\n","  while True:\n","    action = env.action_space.sample()\n","    next_obs, reward, done, info, _ = env.step(action)                      # taking sampled action on environment\n","    buffer.store((obs, action, reward, next_obs, done))                      # storing the st, at, rt+1, st+1 into buffer\n","    episode_reward += reward\n","    episode_steps += 1\n","    count += 1\n","    obs = next_obs\n","    if len(buffer) > batch_size:                                     # if buffer have more new samples than batch size (32); trainig will be done\n","      loss = train(buffer, target_net, eval_net, gamma, optimizer, batch_size, loss_fn, count, update_freq)\n","    if done:\n","      if not weight_reward:\n","        weight_reward = reward_total\n","      else:\n","        weight_reward = 0.99 * weight_reward + 0.01 * reward_total          # a relative current episode reward with past episodes reward\n","      if (i+1) % 10 == 0:\n","        print('episode: {}\\treward: {}\\tweight_reward: {:.3f}\\tepisode loss: {:.3f}'.format(i+1, reward_total, weight_reward, loss))\n","      break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"id":"HbQNC3RlGvmv","executionInfo":{"status":"error","timestamp":1686736158881,"user_tz":-330,"elapsed":576845,"user":{"displayName":"Lukmanul Hakeem M","userId":"17183038146671070294"}},"outputId":"ff0987b5-6b45-45ce-d216-0df160b6737b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-0c1155434699>:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  return (torch.FloatTensor(observations),\n","<ipython-input-5-ea7aba6de97f>:8: UserWarning: Using a target size (torch.Size([128, 128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  loss = F.mse_loss(q_vals, expected_q_vals)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-d3f424549f47>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m                                     \u001b[0;31m# if buffer have more new samples than batch size (32); trainig will be done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mweight_reward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-ea7aba6de97f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(buffer, target_model, eval_model, gamma, optimizer, batch_size, loss_fn, count, update_freq)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# set eval_model gradient to none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# computes the gradient w.r.t loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# Performs a single optimization step (parameter update)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}